%---------change this for every latex homework
\def\yourid{rtg5xkh}   % replace with your UVA computing ID
\def\collabs{ra9ha}
\def\sources{Cormen, et al, Introduction to Algorithms.}
% -----------------------------------------------------
\def\duedate{Friday, February 18, 2022 at 11:30 pm }
\def\duelocation{via Gradescope}
\def\htype{Basic}
\def\hunit{A}
\def\hnumber{3}
\def\course{{cs4102 - algorithms - spring 2022}}%------
%-------------------------------------
%-------------------------------------

\documentclass[10pt]{article}
\usepackage[colorlinks,urlcolor=blue]{hyperref}
\usepackage[osf]{mathpazo}
\usepackage{amsmath,amsfonts,graphicx}
\usepackage{latexsym}
\usepackage[top=1in,bottom=1.4in,left=1.25in,right=1.25in,centering,letterpaper]{geometry}
\usepackage{color}
\definecolor{mdb}{rgb}{0.1,0.6,0.4} 
\definecolor{cit}{rgb}{0.05,0.2,0.45} 
\pagestyle{myheadings}
\markboth{\yourid}{\yourid}
\usepackage{clrscode}

\newenvironment{proof}{\par\noindent{\it Proof.}\hspace*{1em}}{$\Box$\bigskip}
\newcommand{\handout}{
   \renewcommand{\thepage}{Unit \hunit: \htype~Homework \hnumber~-~\arabic{page}}
   \noindent
   \begin{center}
      \vbox{
    \hbox to \columnwidth {\sc{\course} \hfill}
    \vspace{-2mm}
       \hbox to \columnwidth {\sc due \MakeLowercase{\duedate} \duelocation\hfill {\Huge\color{mdb}\hunit\hnumber{\Large\MakeLowercase{\htype}}(\yourid)}}
      }
   \end{center}
   \vspace*{1mm}
   \hrule
   \vspace*{1mm}
    {\footnotesize \textbf{Collaboration Policy:} You are encouraged to collaborate with up to 3 other students, but all work submitted must be your own {\em independently} written solution. List the computing ids of all of your collaborators in the \texttt{collabs} command at the top of the tex file. Do not share written notes, documents (including Google docs, Overleaf docs, discussion notes, PDFs), or code.  Do not seek published or online solutions for any assignments. If you use any published or online resources (which may not include solutions) when completing this assignment, be sure to cite by naming the book etc.\ or listing a website's URL. Do not submit a solution that you are unable to explain orally to a member of the course staff. Any solutions that share similar text/code will be considered in breach of this policy. Please refer to the syllabus for a complete description of the collaboration policy.
   \vspace*{1mm}
    \hrule
    \vspace*{2mm}
    \noindent
    \textbf{Collaborators}: \collabs\\
    \textbf{Sources}: \sources}
    \vspace*{2mm}
    \hrule
    \vskip 2em
}

%\newcommand{\solution}[1]{\color{blue}\hfill\break\noindent\textbf{Solution:} #1\color{black}}
%\newcommand{\altsolution}[1]{\color{blue}\hfill\break\noindent\textbf{Solution (Alternative):} #1\color{black}}

\newcommand{\solution}[1]{}
\newcommand{\altsolution}[1]{}

\newcommand{\bit}[1]{\{0,1\}^{ #1 }}
%\dontprintsemicolon
%\linesnumbered
\newtheorem{problem}{\sc\color{cit}problem}
\newtheorem{practice}{\sc\color{cit}practice}
\newtheorem{lemma}{Lemma}
\newtheorem{definition}{Definition}
\newtheorem{theorem}{Theorem}

\newcommand{\Z}{\mathbb{Z}} % This might be useful for Integers!

\begin{document}
\thispagestyle{empty}
\handout

%----Begin your modifications here


%--- Problem 1 ------------------------------------------------------------------------------
\begin{problem} QuickSort \end{problem}

    \begin{enumerate}   
    	\item Briefly describe a scenario when Quicksort runs in $O(n \log n)$ time.

    	\textbf{Solution:}  \emph{Quicksort will run in $O(n \log n)$ time in the best case, when for each value, p, on which we partition the list (or sublist), p happens to be the median of the sublist the algorithm is currently working on.}

        \item For Quicksort to be a stable sort when sorting a list with non-unique values, the Partition algorithm it uses would have to have a certain property (or would have to behave a certain way).  In a sentence or two, explain what would have to be true of Partition for it to result in a stable Quicksort. (Note: we're not asking you to analyze or explain a particular {\em implementation} of Partition, but to describe a general behavior or property.)
        
        \textbf{Solution:}  \emph{
            The Partition algorithm would need to treat values that are later on in the list and $== p$ as "greater than" p, and it would need to treat values that come sooner than p and $== p$ as "less than" p. Thus the sory would be stable because all duplicate values would remain in their original order after the sort is done.
        }
        
    \end{enumerate} 


%--- Problem 2 ------------------------------------------------------------------------------
\begin{problem} QuickSelect and Median of Medians \end{problem}

    \begin{enumerate}   
    	\item When we add the median-of-medians method to QuickSelect in order to find a good pivot for QuickSelect, name the algorithm we use to find the median value in the list of medians from the 5-element ``chunks".
    	
    	\textbf{Solution:}  \emph{
            Quickselect (again, recursively).
        }

        \item Let's say we used the median-of-medians method to find a ``pretty good" pivot and used that value for the Partition we use for Quicksort.  (We're {\emph not} using that value with QuickSelect to find the real median, but instead we'll just use this ``pretty good" value for the pivot value before we call QuickSort recursively.)  Fill in the blanks in this recurrence to show the time-complexity Quicksort if the size of the two sub-lists on either side of the pivot were as uneven as possible in this situation:
                $$ T(n) \approx T( ?? ) + T( ?? ) + \Theta(n)$$
        Replace each ``??" with some fraction of $n$, such as $ 0.5 n$ or $ 0.95 n$ etc.
        \textbf{Solution:} \\
        $$ T(n) \approx T(.7n) + T(.3n) + \Theta(n)$$ \\
        \emph {Since the median of medians algorithm will find a value that is within the middle 40\% of values, a 30\% and 70\% split between the two sublists is the most uneven that is possible.}
    \end{enumerate} 


%--- Problem 3 ------------------------------------------------------------------------------
\begin{problem} Other Divide and Conquer Problems \end{problem}

    \begin{enumerate}   
    	\item What trade-off did the arithmetic “trick” of both Karatsuba's algorithm allow us to make, compared with the initial divide and conquer solutions for the problem that we first discussed? Why did making that change reduce the overall run-time of the algorithm? \\
        \textbf{Solution:} \\
        \emph{
            Using substitution and rearranging terms, Karatsuba's algorithm allowed us to only need to make one multiplication in each subproblem (instead of the 2 multiplications needed in D \& C). His strategy used more additions to make this possible. This reduced the overall runtime of the algorithm because multiplications are much more expensive than additions.
        }
        \item Would it be feasible (without reducing the time complexity) to implement the closest pair of points algorithm from class by handling the points in the runway first, and then recursively solving the left and right sub-problems?  If your answer is "no", briefly explain the reason why. \\
        \textbf{Solution:} \\
        \emph{No. The width of the runway is dependent on the minimum distance between the closest pair of points on the left and the right, so it would not be possible to do that step first.}

        \item In the closest pair of points algorithm, when processing points in the runway, which of the following are true?
    		\begin{enumerate} 
    		\item It's possible that the pair of points we're seeking could be in the runway and both points could be on the same side of the midpoint. \\
    		\textbf{Solution:} \\
            \emph{True. The algorithm would have already found that pair of points if they were close enough together and on the same side of the midpoint, however if they represent the true minimum they would be found again by the step that finds the minimum in the runway. Thus the minimum of the left, right, and runway would just be that pair.}
   		    \item The algorithm will have a worse time-complexity if we needed to check 50 points above a given point instead of 7 (as we did in class). \\
   		    \textbf{Solution:} \\
            \emph{False. 7 and 50 are both constants so they will not influence the $\mathbb{O}/\Theta/\Omega$ time complexity of the algorithm, even if they may add a small amount of time to the algorithm in reality. Thus the increase from 7 to 50 will not make the time complexity of the algorithm worse.}
       		\item The algorithm will have a worse time-complexity if we needed to check $\sqrt{n}$ points above a given point instead of 7 (as we did in class). \\
       		\textbf{Solution:} \\
            \emph{True. This would make the time complexity worse because $\sqrt{n}$ is not a constant. It grows as n grows, thus it must be added to the time complexity, and in this case it would make the algorithm slower.}
    		\end{enumerate} 
    \end{enumerate} 


%--- Problem 4 ------------------------------------------------------------------------------
\begin{problem} Lower Bounds Proof for Comparison Sorts \end{problem}

In class, we saw a lower-bounds proof that general comparison sorts are always $\Omega(n \log n)$. Answer the following questions about the decision tree proof that we did.
    \begin{enumerate}   
    	\item What did the internal nodes in the decision tree represent? \\
    	\textbf{Solution:} \\ \emph{Each internal node represented a comparison that the sorting algorithm might need to execute.}
        \item What did leaf nodes of the decision tree represent? \\
        \textbf{Solution:} \\ \emph{Each leaf node represented a permutation of the elements that need to be sorted.}
    \end{enumerate}

\begin{problem} Gradescope Submission \end{problem}
Submit a version of this \verb|.tex| file to Gradescope with your solutions added.  You should only submit your \verb|.pdf| and \verb|.tex| files.

% Bibliography
%\bibliographystyle{plain}
%\bibliography{bibliography}

\end{document}

